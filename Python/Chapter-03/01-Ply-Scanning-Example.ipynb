{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "<link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       ".container { width: 100% }\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 2.2em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0, 80, 120);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 1.9em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(200,100,0);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(94,127,192);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".text_cell_render em {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    color:        blue;\n",
       "    background-color: rgb(255,220,180);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   100;\n",
       "}\n",
       "\n",
       ".text_cell_render b {\n",
       "    color:            rgb(255,195,195);\n",
       "    background-color: rgb(0,0,0);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render u {\n",
       "    color:            blue;\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render tt {\n",
       "    font-size:    120%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   150;\n",
       "}\n",
       "\n",
       ".Codemirror {\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 100%;\n",
       "}\n",
       "\n",
       "#fancy {\n",
       "    font-family:      Georgia;\n",
       "    position:         relative;\n",
       "    float:            left;\n",
       "    border:           2px solid red;\n",
       "    width:            600px;\n",
       "    padding-left:     20px;\n",
       "    padding-right:    20px;\n",
       "    padding-top:      10px;\n",
       "    font-family:      'Sacramento', cursive;\n",
       "    font-size:        26px;\n",
       "    background-color: #F4EBF3;\n",
       "    border-radius:    15px;\n",
       "}\n",
       "\n",
       "</Style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open('../style.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example has been extracted from the official documentation of Ply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tokenizer for Numbers and the Arithmetical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `ply.lex` contains the code that is necessary to create a scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ply in c:\\users\\lkemmet\\onedrive - daimler truck\\documents\\github\\.venv\\lib\\site-packages (3.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a definition of the <em style=\"color:blue\">token names</em>.  Note that all token names have to start with \n",
    "a capital letter.  We have to define these token names as a list with the name `tokens`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "   'NUMBER',\n",
    "   'PLUS',\n",
    "   'MINUS',\n",
    "   'TIMES',\n",
    "   'DIVIDE',\n",
    "   'LPAREN',\n",
    "   'RPAREN'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to define these tokens:\n",
    " - *immediate token definitions* define the token by assigning a regular expression to a variable of the form `t_name`,\n",
    "   where `name` is the name of the token that is defined.\n",
    " - *functional token definitions* define the token via a function.  The regular expression that defines the token\n",
    "   is the string appearing in the first line of the function body.\n",
    "   \n",
    "We see examples below.  We start with the *immediate token definitions*.  Note that we have to use *raw strings* here to prevent \n",
    "the expansion of backslash sequences.  Furthermore, those symbols that are interpreted as *operator* symbols inside a regular expression have to be escaped with a backslash character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_PLUS    = r'\\+'\n",
    "t_MINUS   = r'-'\n",
    "t_TIMES   = r'\\*'\n",
    "t_DIVIDE  = r'/'\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to transform the value of a token, we can define the token via a function.  In that case, the first line of the function \n",
    "has to be a string that is a regular expression.  This regular expression then defines the token.  After that,\n",
    "we can add code to transform the token.  The string that makes up the token is stored in `t.value`.  Below, this string\n",
    "is cast into an integer via the predefined function `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NUMBER(t):\n",
    "    r'0|[1-9][0-9]*'\n",
    "    t.value = int(t.value)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule below is used to keep track of line numbers. We use the function `len` since there might be\n",
    "more than one newline.  The member variable `lexer.lineno` keeps track of the current line number.  This variable\n",
    "is maintained so that we are able to specify the precise location of unkown characters in error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += len(t.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword `t_ignore` specifies those characters that should be discarded.\n",
    "In the following cell it specifies that space characters and tabulator characters are to be ignored.  Note that we **must not** use a raw string here, since otherwise `\\t` would not denote a tabulator character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ignore = ' \\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All characters not recognized by any of the defined tokens are handled by the function `t_error`.\n",
    "The function `t.lexer.skip(1)` skips one character, which is the character that has not been recognized. Scanning resumes after this character has been discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    print(f\"Illegal character '{t.value[0]}' at line {t.lexer.lineno}.\")\n",
    "    print(f\"This is the {t.lexpos}th character.\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the function `lex.lex()` creates the lexer specified above.  Since this code is expected to be part \n",
    "of some Python file but really isn't part of a file since it is placed in a Jupyter notebook we have to set the variable \n",
    "`__file__` manually to fool the system into believing that the code given above is located in a file \n",
    "called `hugo.py`.  The name `hugo` is totally irrelevant and could be replaced by any other name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lex: tokens   = ['NUMBER', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN']\n",
      "lex: literals = ''\n",
      "lex: states   = {'INITIAL': 'inclusive'}\n",
      "lex: Adding rule t_NUMBER -> '0|[1-9][0-9]*' (state 'INITIAL')\n",
      "lex: Adding rule t_newline -> '\\n+' (state 'INITIAL')\n",
      "lex: Adding rule t_PLUS -> '\\+' (state 'INITIAL')\n",
      "lex: Adding rule t_TIMES -> '\\*' (state 'INITIAL')\n",
      "lex: Adding rule t_LPAREN -> '\\(' (state 'INITIAL')\n",
      "lex: Adding rule t_RPAREN -> '\\)' (state 'INITIAL')\n",
      "lex: Adding rule t_MINUS -> '-' (state 'INITIAL')\n",
      "lex: Adding rule t_DIVIDE -> '/' (state 'INITIAL')\n",
      "lex: ==== MASTER REGEXS FOLLOW ====\n",
      "lex: state 'INITIAL' : regex[0] = '(?P<t_NUMBER>0|[1-9][0-9]*)|(?P<t_newline>\\n+)|(?P<t_PLUS>\\+)|(?P<t_TIMES>\\*)|(?P<t_LPAREN>\\()|(?P<t_RPAREN>\\))|(?P<t_MINUS>-)|(?P<t_DIVIDE>/)'\n"
     ]
    }
   ],
   "source": [
    "__file__ = 'hugo'\n",
    "lexer = lex.lex(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `lexer` is the scanner that has been created by the previous command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ply.lex.Lexer at 0x2549c291a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the generated scanner, that is stored in `lexer`, with the following string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "       3 + 4 * 10 + 007 + (-20) * 2\n",
    "       42\n",
    "       a\n",
    "       \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us feed the scanner with the string `data`.  This is done by calling the method `input` of the generated scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n       3 + 4 * 10 + 007 + (-20) * 2\\n       42\\n       a\\n       '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have set the line number to `1` before scanning in order to be able to run the scanner multiple times, since each time the scanner runs the line number is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer.lineno = 1\n",
    "lexer.input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put the lexer to work by using it as an *iterable*.  This way, we can simply iterate over all the tokens that our scanner recognizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(NUMBER,3,2,8)\n",
      "LexToken(PLUS,'+',2,10)\n",
      "LexToken(NUMBER,4,2,12)\n",
      "LexToken(TIMES,'*',2,14)\n",
      "LexToken(NUMBER,10,2,16)\n",
      "LexToken(PLUS,'+',2,19)\n",
      "LexToken(NUMBER,0,2,21)\n",
      "LexToken(NUMBER,0,2,22)\n",
      "LexToken(NUMBER,7,2,23)\n",
      "LexToken(PLUS,'+',2,25)\n",
      "LexToken(LPAREN,'(',2,27)\n",
      "LexToken(MINUS,'-',2,28)\n",
      "LexToken(NUMBER,20,2,29)\n",
      "LexToken(RPAREN,')',2,31)\n",
      "LexToken(TIMES,'*',2,33)\n",
      "LexToken(NUMBER,2,2,35)\n",
      "LexToken(NUMBER,42,3,44)\n",
      "Illegal character 'a' at line 4.\n",
      "This is the 54th character.\n"
     ]
    }
   ],
   "source": [
    "for token in lexer:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the generated tokens contain four pieces of information:\n",
    " 1. The *type* of the token.\n",
    " 2. The *value* of the token.  This is either a number or a string.\n",
    " 3. The *line number* of the token.  The line number starts with 1.\n",
    "    However, note that the first line of `data` is empty.\n",
    " 4. The *character count*.  For example, the last token is the $54^{\\textrm{th}}$ character.\n",
    "    The character count starts with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
